{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBmwaDOqvU_-",
        "colab_type": "text"
      },
      "source": [
        "# Topic 1 Overview of Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff1cJre4vME_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2UwZR6jvONy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovMIm1O4vPky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxDOnc69vRTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Cuda Current Device: \", torch.cuda.current_device())\n",
        "print(\"Cude Device Count: \", torch.cuda.device_count())\n",
        "print(\"Cude Device Name: \", torch.cuda.get_device_name(0))\n",
        "print(\"Cude Device Available : \", torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KufJMtkSCAnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTXm_2dZh63x",
        "colab_type": "text"
      },
      "source": [
        "# Topic 2 Basic Pytorch Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj5zdxGUf6IH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Torch Vector\n",
        "a = [1, 2, 3]\n",
        "b = torch.Tensor(a)\n",
        "# b = torch.FloatTensor(a)\n",
        "# b = torch.DoubleTensor(a)\n",
        "# b = torch.IntTensor(a)\n",
        "# b = torch.LongTensor(a)\n",
        "print(b)\n",
        "print(b[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXQCPOCAf-i_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Torch Matrix\n",
        "a = [[1, 2, 3], [4, 5, 6]]\n",
        "b = torch.Tensor(a)\n",
        "print(b)\n",
        "print(b[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XN85oeHgBb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a 3D Tensor\n",
        "a = [[[1., 2.], [3., 4.]],\n",
        "     [[5., 6.], [7., 8.]]]\n",
        "b = torch.Tensor(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yOsyKiSgE3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Conversion from Tensor to numpy\n",
        "a = torch.Tensor([3])\n",
        "print(a)\n",
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jHE-i1znl7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Conversion from numpy to Tensor\n",
        "import numpy as np\n",
        "a = np.arange(6).reshape(2,3)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzDb1BOehNoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Numpy functions\n",
        "a = [1,2,3,4]\n",
        "a_np = np.sum(a)\n",
        "a_np = np.mean(a)\n",
        "print(a_np)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2u2QLZnhXa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Torch functions\n",
        "b = torch.Tensor(a)\n",
        "b_t = torch.sum(b)\n",
        "b_t = torch.mean(b)\n",
        "b_t = torch.max(b)\n",
        "print(b_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmI9Q9Ghh0my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensor operations\n",
        "a = torch.Tensor([1,1])\n",
        "b = torch.Tensor([2,2])\n",
        "print(a+b)\n",
        "print(torch.add(a, b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJCTD-SYbDy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensor operations with GPU\n",
        "a = torch.Tensor([1,1]).to(device)\n",
        "b = torch.Tensor([2,2]).to(device)\n",
        "c = a+b\n",
        "print(c)\n",
        "print(c.cpu().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRYeznRviUw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ex: Tensor Operation with GPU\n",
        "a = torch.Tensor([3]).to(device)\n",
        "b = torch.Tensor([4]).to(device)\n",
        "c = torch.Tensor([5]).to(device)\n",
        "d = a*b+c\n",
        "print(d)\n",
        "print(d.cpu().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6332HGEhcqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Torch matrix multiplication\n",
        "\n",
        "a_t = torch.Tensor(a)\n",
        "b_t = torch.Tensor(b)\n",
        "c_t = torch.mm(a_t,b_t)\n",
        "print(c_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbdW_-ZSZtbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ex: Matrix operation\n",
        "x = torch.Tensor([[1,1]])\n",
        "w = torch.Tensor([[1,2],[3,4]])\n",
        "b = torch.Tensor([[2,2]])\n",
        "print(torch.mm(x,w)+b)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHLAtiyihloR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate Special Torch Tensors\n",
        "a = torch.diag(torch.Tensor([1,2,3]))\n",
        "a = torch.eye(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsS5foAshq1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Torch linspace\n",
        "a_np = np.linspace(1,5,10)\n",
        "a_t = torch.linspace(1,5,10)\n",
        "print(a_np)\n",
        "print(a_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzI6VkgMhvvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create uniform random numbers from 0 to 1\n",
        "a = torch.rand(5, 3)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbWciFathsmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create gaussion random numbers with mean 0 and std 1\n",
        "a = torch.randn(5, 3)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjqGcmRfhoJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Torch Max\n",
        "a = torch.Tensor([[1,0,0],[1,0,0],[0,1,0],[0,0,1]])\n",
        "print(torch.max(a,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjCvcceTicor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape a torch tensor\n",
        "a = torch.linspace(1,10,10).view(2,5)\n",
        "a = torch.linspace(1,10,10).reshape(2,5)\n",
        "a = torch.linspace(1,10,10).view(-1,2)\n",
        "a = torch.linspace(1,10,10).reshape(-1,2)\n",
        "\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wWf1I4LucDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unsqueeze and squeeze dimensions\n",
        "x = torch.linspace(0, 5, 5)\n",
        "print(x)\n",
        "x = torch.unsqueeze(x, dim=0) \n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdMoDX2g66fi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.linspace(0, 5, 5)\n",
        "print(x)\n",
        "x = torch.unsqueeze(x, dim=1) \n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8KgXNGtulXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Concatenate\n",
        "x = torch.Tensor([1,2,3])\n",
        "y = torch.cat((x,x,x))\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raZtHK1aupRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transpose\n",
        "x = torch.Tensor([[1,2],[3,4]])\n",
        "y = torch.t(x)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdb3LbkP5_Ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ex: Tensor Operations\n",
        "\n",
        "x = torch.Tensor([1,1])\n",
        "x = torch.unsqueeze(x,dim=0)\n",
        "#print(x)\n",
        "w = torch.Tensor([[1,2],[3,4]])\n",
        "#print(w)\n",
        "b = torch.Tensor([[2],[2]])\n",
        "b = torch.t(b)\n",
        "#print(b)\n",
        "y = torch.mm(b,w)+x\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTniAZQFh3gK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Appendix: Numpy Tutorial\n",
        "# Matrix Multiplication\n",
        "\n",
        "a = np.array([[1,1],[2,2]])\n",
        "b = np.array([3,3])\n",
        "print(np.matmul(b,a))\n",
        "print(np.matmul(a,b))\n",
        "print(a.dot(b))\n",
        "print(a.T.dot(b))\n",
        "print(b*a)\n",
        "print(a*b)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyzQPio8ur_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Appendix: Numpy Tutorial\n",
        "# Expand and Squeeze\n",
        "\n",
        "a = np.array([1,3])\n",
        "print(a.shape)\n",
        "b = np.expand_dims(a,axis=0)\n",
        "b = np.expand_dims(a,axis=1)\n",
        "b = a[np.newaxis]\n",
        "print(b.shape)\n",
        "c = np.squeeze(b)\n",
        "print(c.shape)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbNhSJ6_zc4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gradient and Back Propagation\n",
        "x = torch.Tensor([5])\n",
        "x.requires_grad=True\n",
        "y = x*x\n",
        "y.backward()\n",
        "print('x gradient = ', x.grad.numpy())\n",
        "print('x gradient = ', x.detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2zQAtwA0dHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gradient\n",
        "x = torch.Tensor([-2])\n",
        "x.requires_grad=True\n",
        "y = torch.Tensor([5])\n",
        "y.requires_grad=True\n",
        "z = torch.Tensor([-4])\n",
        "z.requires_grad=True\n",
        "f = (x+y)*z    \n",
        "\n",
        "f.backward()\n",
        "print('x gradient = ',x.grad.numpy())    \n",
        "print('y gradient = ',y.grad.numpy())     \n",
        "print('z gradient = ',z.grad.numpy())   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x39nM7ndCrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ex: Gradient\n",
        "x = torch.Tensor([2])\n",
        "x.requires_grad=True\n",
        "w = torch.Tensor([3])\n",
        "w.requires_grad=True\n",
        "b = torch.Tensor([4])\n",
        "b.requires_grad=True\n",
        "y = w * x + b    \n",
        "\n",
        "# Compute gradients\n",
        "y.backward()\n",
        "\n",
        "# Print out the gradients.\n",
        "print('x gradient = ', x.grad.numpy())     \n",
        "print('w gradient = ', w.grad.numpy())    \n",
        "print('b gradient = ', b.grad.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJadEh2k3rhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ex: Gradient\n",
        "x = torch.Tensor([2])\n",
        "x.requires_grad=True\n",
        "y = x**2+5*x+2 \n",
        "y.backward()\n",
        "print('x gradient = ', x.grad.numpy())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18HJGS6f8TCV",
        "colab_type": "text"
      },
      "source": [
        "# Topic 3 Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWODdZGw2h9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMXm6t8SCPfA",
        "colab_type": "text"
      },
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibwFn9rbAP9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))\n",
        "     ])\n",
        "\n",
        "# transform = transforms.Compose(\n",
        "#     [transforms.ToTensor()\n",
        "#      ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8br0HEyIATDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
        "\n",
        "testset = datasets.MNIST(root='./mnist', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD4Q2Qz4ZHof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image,label = next(iter(trainloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DksQMFRZaFF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image.shape,label.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhyr5dPLZt2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image[0][0],cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSm49MChe7oO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mcYbdcjKrcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.imshow(image[i][0], cmap='gray')\n",
        "  plt.title(\"Ground Truth: {}\".format(label[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P_50jUIFXiz",
        "colab_type": "text"
      },
      "source": [
        "## Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxnCtaGJBph2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = datasets.FashionMNIST(root='./fashion_mnist', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = datasets.FashionMNIST(root='./fashion_mnist', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoQYSnxrMyYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image,label = next(iter(trainloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry4j8l-jM1c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.imshow(image[i][0], cmap='gray')\n",
        "  plt.title(\"Ground Truth: {}\".format(label[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDXsP9SSFaNg",
        "colab_type": "text"
      },
      "source": [
        "## CIRAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEaCXcMRNa46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WvLIBW_FJkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhEXHqeji6e8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image,label = next(iter(trainloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uknoRjo9FlVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyFFB_AHZjmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.imshow(image[i][0])\n",
        "  plt.title(\"{}\".format(classes[label[i]]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPXRZX6ibWPJ",
        "colab_type": "text"
      },
      "source": [
        "# Topic 4 Neural Network for Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1qhtFgjH0ml",
        "colab_type": "text"
      },
      "source": [
        "## Simple Linear Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfjbDEBnb5nH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dbXJLdAb-Sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper parameters\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Step 1: Setup\n",
        "X_train = [1,2,3,4,5]\n",
        "y_train = [0,-1.1,-1.8,-3.1,-4.5]\n",
        "\n",
        "X = torch.Tensor(X_train)\n",
        "y = torch.Tensor(y_train)\n",
        "\n",
        "W = torch.rand(1)\n",
        "b = torch.rand(1)\n",
        "\n",
        "W.requires_grad=True\n",
        "b.requires_grad=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO_9eX4gdQjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2: Optimizer\n",
        "optimizer = torch.optim.SGD([W,b], lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q44h-938dTSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 3: Train the Model\n",
        "for i in range(1000):\n",
        "\n",
        "\t# Model\n",
        "    yhat = X*W + b\n",
        "\n",
        "    # Loss Function\n",
        "    loss = (yhat - y).pow(2).sum()\n",
        "    \n",
        "    # Compute gradients and update parameters\n",
        "    optimizer.zero_grad()   \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i%50==0: print('step',i,'loss = {:0.2f}'.format(loss.detach().numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y2wvsDcNSif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 4: Evaluate the Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "W_ = W.detach().numpy()\n",
        "b_ = b.detach().numpy()\n",
        "plt.plot(X_train,y_train,'o')\n",
        "plt.plot(X_train,W_*X_train+b_,'r')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyAhWaDWMn8H",
        "colab_type": "text"
      },
      "source": [
        "## Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFFQYaYJMj2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "x = torch.linspace(-10,10,100)\n",
        "x_np = x.numpy()\n",
        "\n",
        "# Relu Activation Function\n",
        "x_relu = F.relu(x).data.numpy()\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(x_np,x_relu)\n",
        "plt.title('relu')\n",
        "\n",
        "# Sigmoid Activation Function\n",
        "x_sigmoid = F.sigmoid(x).data.numpy()\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(x_np,x_sigmoid)\n",
        "plt.title('sigmoid')\n",
        "\n",
        "# Softplus Activation Function\n",
        "x_softplus = F.softplus(x).data.numpy()\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(x_np,x_softplus)\n",
        "plt.title('softplus')\n",
        "\n",
        "# Hyperbolic Tanh Activation Function\n",
        "x_tanh = F.tanh(x).data.numpy()\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(x_np,x_tanh)\n",
        "plt.title('tanh')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wwjxm4gH_Bf",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network Predictive Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LXn1ZVJIn_k",
        "colab_type": "text"
      },
      "source": [
        "### Step 1 Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns18cp-nepZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataset_path = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"                     \n",
        "dataset = pd.read_csv(dataset_path)\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZRgXF8U5V-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as-f5S9I5YN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = dataset.sample(frac=0.7,random_state=0)\n",
        "x_test = dataset.drop(x_train.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9De5i0275Zzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = x_train.pop('medv')\n",
        "y_test = x_test.pop('medv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uO1NVtF5bOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = (x_train - x_train.mean())/(x_train.max()-x_train.min())\n",
        "x_test = (x_test - x_test.mean())/(x_test.max()-x_test.min())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrMx0mbe6wu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = torch.from_numpy(x_train.values).float()\n",
        "y_train = torch.from_numpy(y_train.values).float()\n",
        "\n",
        "x_test = torch.from_numpy(x_test.values).float()\n",
        "y_test = torch.from_numpy(y_test.values).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImdIPcDcGFAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = torch.unsqueeze(y_train, dim=1) \n",
        "y_test = torch.unsqueeze(y_test, dim=1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yPMcsa5-HCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape, y_train.shape,x_test.shape,y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So5PZ3YhIwzL",
        "colab_type": "text"
      },
      "source": [
        "### Step 2 Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItjYrsuu5dGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(13,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)             \n",
        "        return x\n",
        "\n",
        "model = Model() \n",
        "print(model) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9wclFVOI01a",
        "colab_type": "text"
      },
      "source": [
        "### Step 3 Define the Loss Function and Optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3U04ACC6GNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Loss function\n",
        "\n",
        "loss_func = nn.MSELoss()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OilVgBn66G9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBw7dlX6JPVG",
        "colab_type": "text"
      },
      "source": [
        "### Step 4 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09vfhfgp6aI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1000):\n",
        "\n",
        "\t# Model prediction\n",
        "    yhat = model(x_train)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = loss_func(yhat, y_train)\n",
        "    #loss = F.mse_loss(yhat,y)\n",
        "\n",
        "    # Compute gradients and update parameters     \n",
        "    optimizer.zero_grad()   \n",
        "    loss.backward()         \n",
        "    optimizer.step()       \n",
        "\n",
        "    if i%50==0: print('step',i,'loss = {:0.2f}'.format(loss.detach().numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjw3w75aLzN9",
        "colab_type": "text"
      },
      "source": [
        "### Step 5 Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEJZB0zH6l8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_hat = model(x_test)\n",
        "\n",
        "plt.scatter(y_test.data.numpy(), y_hat.data.numpy())\n",
        "plt.xlabel('True Values [Housing Price]')\n",
        "plt.ylabel('Predictions [Housing Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw3KpSEGA7Ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat.shape,y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XYniWyCOpji",
        "colab_type": "text"
      },
      "source": [
        "## Save and Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkn0gAOtFiL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model,'./regression.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjuqTi1JNa7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model=torch.load('./regression.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9OdIbhTOTcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_hat = new_model(x_test)\n",
        "\n",
        "plt.scatter(y_test.data.numpy(), y_hat.data.numpy())\n",
        "plt.xlabel('True Values [Housing Price]')\n",
        "plt.ylabel('Predictions [Housing Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvelV5hrO2kI",
        "colab_type": "text"
      },
      "source": [
        "## Ex: Predictive Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04GMNiP-P5jD",
        "colab_type": "text"
      },
      "source": [
        "### Step 1 Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGjfmx_YOW50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataset_path = \"https://raw.githubusercontent.com/pandas-dev/pandas/master/pandas/tests/data/iris.csv\"\n",
        "                     \n",
        "dataset = pd.read_csv(dataset_path)\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD3hZcxpO7zp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.dropna()\n",
        "dataset.pop('Name')\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHkS-SueO8Jl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = dataset.sample(frac=0.7,random_state=0)\n",
        "x_test = dataset.drop(x_train.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUPBVmV5O_9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = x_train.pop('SepalWidth')\n",
        "y_test = x_test.pop('SepalWidth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCqBnnnpPHx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = (x_train - x_train.mean())/(x_train.max()-x_train.min())\n",
        "x_test = (x_test - x_test.mean())/(x_test.max()-x_test.min())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGi64hZEPJqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = torch.from_numpy(x_train.values).float()\n",
        "y_train = torch.from_numpy(y_train.values).float()\n",
        "\n",
        "x_test = torch.from_numpy(x_test.values).float()\n",
        "y_test = torch.from_numpy(y_test.values).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey0ZAW46PRN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = torch.unsqueeze(y_train, dim=1) \n",
        "y_test = torch.unsqueeze(y_test, dim=1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtU9lexgPTCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape, y_train.shape,x_test.shape,y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wNP54DhQF0_",
        "colab_type": "text"
      },
      "source": [
        "### Step 2 Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L2u3hPLPVEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(3,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)             \n",
        "        return x\n",
        "\n",
        "model = Model() \n",
        "print(model) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhE7L8cvQPz2",
        "colab_type": "text"
      },
      "source": [
        "### Step 3 Define the Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKRPul_HPZ6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Loss function\n",
        "\n",
        "loss_func = nn.MSELoss()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIPapFsePen0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "learning_rate = 0.0001\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZJ4DgwtQUhK",
        "colab_type": "text"
      },
      "source": [
        "### Step 4 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsR_ml9SPhKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1000):\n",
        "\n",
        "\t# Model prediction\n",
        "    yhat = model(x_train)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = loss_func(yhat, y_train)\n",
        "    #loss = F.mse_loss(yhat,y)\n",
        "\n",
        "    # Compute gradients and update parameters     \n",
        "    optimizer.zero_grad()   \n",
        "    loss.backward()         \n",
        "    optimizer.step()       \n",
        "\n",
        "    if i%50==0: print('step',i,'loss = {:0.2f}'.format(loss.detach().numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIpnqun-Qhcw",
        "colab_type": "text"
      },
      "source": [
        "### Step 5 Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQRpr1_0Pjhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_hat = model(x_test)\n",
        "\n",
        "plt.scatter(y_test.data.numpy(), y_hat.data.numpy())\n",
        "plt.xlabel('True Values Sepal Width')\n",
        "plt.ylabel('Predictions Sepal Width')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xVeTe7aRx89",
        "colab_type": "text"
      },
      "source": [
        "# Topic 5 Neural Network for Classication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f9dWS4jiwLT",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHeyy3IoSZPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))\n",
        "     ])\n",
        "\n",
        "# Hyper Parameters             \n",
        "BATCH_SIZE = 200\n",
        "LR = 0.001 \n",
        "EPOCH = 10\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./mnist', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9NXzwwdi3Lb",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWdKLPJWYRpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)   \n",
        "        return x\n",
        "\n",
        "model = Model() \n",
        "model = model.to(device)\n",
        "print(model) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_zYqeegi-i6",
        "colab_type": "text"
      },
      "source": [
        "### Define the Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5yE7i5cYRwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Function\n",
        "loss_func = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb7yPy8ui_7y",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db2mKFxXY4s-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "def validation():\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for (x,y) in testloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            x = x.reshape(-1,28*28)\n",
        "\n",
        "            yhat = model(x)\n",
        "            loss = loss_func(yhat, y)  \n",
        "\n",
        "            _, y_pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (y_pred == y.data).sum()\n",
        "            acc = correct.double()/total\n",
        "            loss = loss.cpu().detach().numpy()\n",
        "        return acc,loss\n",
        "\n",
        "for epoch in range(EPOCH): \n",
        "\n",
        "    print('Epoch {}/{}'.format(epoch, EPOCH - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    total = 0   \n",
        "    correct = 0 \n",
        "\n",
        "    for i, (x, y) in enumerate(trainloader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        x = x.reshape(-1,28*28)\n",
        "\n",
        "        yhat = model(x)\n",
        "        loss = loss_func(yhat, y)  \n",
        "\n",
        "        optimizer.zero_grad()            \n",
        "        loss.backward()                  \n",
        "        optimizer.step()         \n",
        "      \n",
        "\n",
        "        _, y_pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (y_pred == y.data).sum()\n",
        "\n",
        "    _acc = correct.double()/total\n",
        "    _loss = loss.cpu().detach().numpy()\n",
        "    train_loss.append(_loss)\n",
        "    train_acc.append(_acc)\n",
        "            \n",
        "    _val_acc,_val_loss = validation()\n",
        "    val_loss.append(_val_loss)\n",
        "    val_acc.append(_val_acc)\n",
        "\n",
        "    print('loss: {:.4f} acc: {:.4f} val_loss: {:.4f} val_acc: {:.4f} '.format(_loss,_acc,_val_loss,_val_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYWNEQzzjDdx",
        "colab_type": "text"
      },
      "source": [
        "### Step 5 Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tafi1E0X8H5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch = range(len(train_loss))\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,train_loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,train_acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN1wlpgxhOGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_val_acc,_val_loss = validation()\n",
        "\n",
        "print('Test accuracy: {:.4f}'.format(_val_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plumZ8NLX2Nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7wv4vI5eZjO",
        "colab_type": "text"
      },
      "source": [
        "## Ex: Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n5DkX1IIDOV",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWqDZIRWedpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))\n",
        "     ])\n",
        "\n",
        "# Hyper Parameters             \n",
        "BATCH_SIZE = 100\n",
        "LR = 0.001 \n",
        "EPOCH = 10\n",
        "\n",
        "trainset = torchvision.datasets.FashionMNIST(root='./fashion_mnist', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(root='./fashion_mnist', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD736TNIIAkx",
        "colab_type": "text"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgjTa0Qserd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)       \n",
        "        return x\n",
        "\n",
        "model = Model() \n",
        "model = model.to(device)\n",
        "print(model) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UGAZ04LIGaM",
        "colab_type": "text"
      },
      "source": [
        "### Define the loss function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlUfPP3Ee3ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Function\n",
        "loss_func = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roAbww2Ve8A3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "306NmZEaUbIu",
        "colab": {}
      },
      "source": [
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "def validation():\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for (x,y) in testloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            x = x.reshape(-1,28*28)\n",
        "\n",
        "            yhat = model(x)\n",
        "            loss = loss_func(yhat, y)  \n",
        "\n",
        "            _, y_pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (y_pred == y.data).sum()\n",
        "            acc = correct.double()/total\n",
        "            loss = loss.cpu().detach().numpy()\n",
        "        return acc,loss\n",
        "\n",
        "for epoch in range(EPOCH): \n",
        "\n",
        "    print('Epoch {}/{}'.format(epoch, EPOCH - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    total = 0   \n",
        "    correct = 0 \n",
        "\n",
        "    for i, (x, y) in enumerate(trainloader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        x = x.reshape(-1,28*28)\n",
        "\n",
        "        yhat = model(x)\n",
        "        loss = loss_func(yhat, y)  \n",
        "\n",
        "        optimizer.zero_grad()            \n",
        "        loss.backward()                  \n",
        "        optimizer.step()         \n",
        "      \n",
        "\n",
        "        _, y_pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (y_pred == y.data).sum()\n",
        "\n",
        "    _acc = correct.double()/total\n",
        "    _loss = loss.cpu().detach().numpy()\n",
        "    train_loss.append(_loss)\n",
        "    train_acc.append(_acc)\n",
        "            \n",
        "    _val_acc,_val_loss = validation()\n",
        "    val_loss.append(_val_loss)\n",
        "    val_acc.append(_val_acc)\n",
        "\n",
        "    print('loss: {:.4f} acc: {:.4f} val_loss: {:.4f} val_acc: {:.4f} '.format(_loss,_acc,_val_loss,_val_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j3uo7mRHyBU",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HGNdB4pdE9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch = range(len(train_loss))\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,train_loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,train_acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N4PAR54fASi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_val_acc,_val_loss = validation()\n",
        "\n",
        "print('Test accuracy: {:.4f}'.format(_val_acc))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kze0f3VXjIFa",
        "colab_type": "text"
      },
      "source": [
        "# Topic 6 Convolutional Neural Networks (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfVmcqnUdW43",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cezdjeMTu45G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))\n",
        "     ])\n",
        "\n",
        "# Hyper Parameters             \n",
        "BATCH_SIZE = 200\n",
        "LR = 0.001 \n",
        "EPOCH = 10\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True,num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./mnist', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False,num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzufVUondZt4",
        "colab_type": "text"
      },
      "source": [
        "## Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaur5V-uTpQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1,16,3,1,1)\n",
        "        self.conv2 = nn.Conv2d(16,32,3,1,1)\n",
        "        self.fc1 = nn.Linear(32*7*7,128)\n",
        "        self.fc2 = nn.Linear(128, 10)     \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view( x.size(0),-1) \n",
        "        x = F.relu(self.fc1(x))              \n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Model()\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LMjouRZdb_o",
        "colab_type": "text"
      },
      "source": [
        "## Define Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8lKoivsVE2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Function\n",
        "loss_func = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB-1pch4dehW",
        "colab_type": "text"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9yMLMhJUqms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "def validation():\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for (x,y) in testloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            yhat = model(x)\n",
        "            loss = loss_func(yhat, y)  \n",
        "\n",
        "            _, y_pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (y_pred == y.data).sum()\n",
        "            acc = correct.double()/total\n",
        "            loss = loss.cpu().detach().numpy()\n",
        "        return acc,loss\n",
        "\n",
        "for epoch in range(EPOCH): \n",
        "\n",
        "    print('Epoch {}/{}'.format(epoch, EPOCH - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    total = 0   \n",
        "    correct = 0 \n",
        "\n",
        "    for i, (x, y) in enumerate(trainloader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        yhat = model(x)\n",
        "        loss = loss_func(yhat, y)  \n",
        "\n",
        "        optimizer.zero_grad()            \n",
        "        loss.backward()                  \n",
        "        optimizer.step()         \n",
        "      \n",
        "\n",
        "        _, y_pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (y_pred == y.data).sum()\n",
        "\n",
        "    _acc = correct.double()/total\n",
        "    _loss = loss.cpu().detach().numpy()\n",
        "    train_loss.append(_loss)\n",
        "    train_acc.append(_acc)\n",
        "            \n",
        "    _val_acc,_val_loss = validation()\n",
        "    val_loss.append(_val_loss)\n",
        "    val_acc.append(_val_acc)\n",
        "\n",
        "    print('loss: {:.4f} acc: {:.4f} val_loss: {:.4f} val_acc: {:.4f} '.format(_loss,_acc,_val_loss,_val_acc))\n",
        "           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxGU64eydj2E",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6f0sEAbLw6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch = range(len(train_loss))\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,train_loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,train_acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9jqqRiqy34I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_val_acc,_val_loss = validation()\n",
        "\n",
        "print('Test accuracy: {:.4f}'.format(_val_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RIGyBLzdtGt",
        "colab_type": "text"
      },
      "source": [
        "## Ex: CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koAag2qVd3S6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ])\n",
        "\n",
        "#Hyper Parameters\n",
        "BATCH_SIZE = 200\n",
        "LR = 0.001 \n",
        "EPOCH = 10\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNUZsHqOd60G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3,16,3,1,1)\n",
        "        self.conv2 = nn.Conv2d(16,32,3,1,1)\n",
        "        self.fc1 = nn.Linear(32*8*8,128)\n",
        "        self.fc2 = nn.Linear(128, 10)     \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view( x.size(0),-1) \n",
        "        x = F.relu(self.fc1(x))              \n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Model()\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcQiiffzd_WG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Function\n",
        "loss_func = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbJoRh0ueKHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "def validation():\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for (x,y) in testloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            yhat = model(x)\n",
        "            loss = loss_func(yhat, y)  \n",
        "\n",
        "            _, y_pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (y_pred == y.data).sum()\n",
        "            acc = correct.double()/total\n",
        "            loss = loss.cpu().detach().numpy()\n",
        "        return acc,loss\n",
        "\n",
        "for epoch in range(EPOCH): \n",
        "\n",
        "    print('Epoch {}/{}'.format(epoch, EPOCH - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    total = 0   \n",
        "    correct = 0 \n",
        "\n",
        "    for i, (x, y) in enumerate(trainloader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        yhat = model(x)\n",
        "        loss = loss_func(yhat, y)  \n",
        "\n",
        "        optimizer.zero_grad()            \n",
        "        loss.backward()                  \n",
        "        optimizer.step()         \n",
        "      \n",
        "\n",
        "        _, y_pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (y_pred == y.data).sum()\n",
        "\n",
        "    _acc = correct.double()/total\n",
        "    _loss = loss.cpu().detach().numpy()\n",
        "    train_loss.append(_loss)\n",
        "    train_acc.append(_acc)\n",
        "            \n",
        "    _val_acc,_val_loss = validation()\n",
        "    val_loss.append(_val_loss)\n",
        "    val_acc.append(_val_acc)\n",
        "\n",
        "    print('loss: {:.4f} acc: {:.4f} val_loss: {:.4f} val_acc: {:.4f} '.format(_loss,_acc,_val_loss,_val_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Qq3sQdeNpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch = range(len(train_loss))\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,train_loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,train_acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xDZ2YFzexLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_val_acc,_val_loss = validation()\n",
        "\n",
        "print('Test accuracy: {:.4f}'.format(_val_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kx1B_1KiGVz",
        "colab_type": "text"
      },
      "source": [
        "# Topic 7 Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hGsXqK_4nrk",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oAXrvtQoEdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))\n",
        "     ])\n",
        "           \n",
        "# Hyper-parameters\n",
        "sequence_length = 28\n",
        "input_size = 28\n",
        "hidden_size = 128\n",
        "num_layers = 1\n",
        "num_classes = 10\n",
        "batch_size = 200\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./mnist', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV-2363H4uRP",
        "colab_type": "text"
      },
      "source": [
        "## Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7Hy7c7Gpys_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Set initial hidden and cell states \n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "        # Forward propagate LSTM\n",
        "        x, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        \n",
        "        # Decode the hidden state of the last time step\n",
        "        x = self.fc(x[:, -1, :])\n",
        "        return x\n",
        "\n",
        "model = Model(input_size, hidden_size, num_layers, num_classes)\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_YfmD6K4w9T",
        "colab_type": "text"
      },
      "source": [
        "## Define Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVCs2hLprLNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Function\n",
        "loss_func = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d15eK7p40K_",
        "colab_type": "text"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUmmo3odXU5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "def validation():\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for (x,y) in testloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            x = x.reshape(-1, sequence_length, input_size)\n",
        "\n",
        "            yhat = model(x)\n",
        "            loss = loss_func(yhat, y)  \n",
        "\n",
        "            _, y_pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (y_pred == y.data).sum()\n",
        "            acc = correct.double()/total\n",
        "            loss = loss.cpu().detach().numpy()\n",
        "        return acc,loss\n",
        "\n",
        "for epoch in range(EPOCH): \n",
        "\n",
        "    print('Epoch {}/{}'.format(epoch, EPOCH - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    total = 0   \n",
        "    correct = 0 \n",
        "\n",
        "    for i, (x, y) in enumerate(trainloader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        x = x.reshape(-1, sequence_length, input_size)\n",
        "\n",
        "        yhat = model(x)\n",
        "        loss = loss_func(yhat, y)  \n",
        "\n",
        "        optimizer.zero_grad()            \n",
        "        loss.backward()                  \n",
        "        optimizer.step()         \n",
        "      \n",
        "\n",
        "        _, y_pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (y_pred == y.data).sum()\n",
        "\n",
        "    _acc = correct.double()/total\n",
        "    _loss = loss.cpu().detach().numpy()\n",
        "    train_loss.append(_loss)\n",
        "    train_acc.append(_acc)\n",
        "            \n",
        "    _val_acc,_val_loss = validation()\n",
        "    val_loss.append(_val_loss)\n",
        "    val_acc.append(_val_acc)\n",
        "\n",
        "    print('loss: {:.4f} acc: {:.4f} val_loss: {:.4f} val_acc: {:.4f} '.format(_loss,_acc,_val_loss,_val_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjX4fqMElHsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch = range(len(train_loss))\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,train_loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,train_acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wby0oXrUlJ6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_val_acc,_val_loss = validation()\n",
        "\n",
        "print('Test accuracy: {:.4f}'.format(_val_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H977BgUKNauY",
        "colab_type": "text"
      },
      "source": [
        "## Ex: RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cQZO2EzBHF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ])\n",
        "\n",
        "# Hyper-parameters\n",
        "sequence_length = 32*3\n",
        "input_size = 32\n",
        "hidden_size = 128\n",
        "num_layers = 1\n",
        "num_classes = 10\n",
        "batch_size = 200\n",
        "num_epochs = 10\n",
        "learning_rate = 0.01\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXiUmPswNiM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Set initial hidden and cell states \n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "        # Forward propagate LSTM\n",
        "        x, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        \n",
        "        # Decode the hidden state of the last time step\n",
        "        x = self.fc(x[:, -1, :])\n",
        "        return x\n",
        "\n",
        "model = Model(input_size, hidden_size, num_layers, num_classes)\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rnd-Wu_OCSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Function\n",
        "loss_func = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbt2CqDyOFwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "def validation():\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for (x,y) in testloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            x = x.reshape(-1, sequence_length, input_size)\n",
        "\n",
        "            yhat = model(x)\n",
        "            loss = loss_func(yhat, y)  \n",
        "\n",
        "            _, y_pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (y_pred == y.data).sum()\n",
        "            acc = correct.double()/total\n",
        "            loss = loss.cpu().detach().numpy()\n",
        "        return acc,loss\n",
        "\n",
        "for epoch in range(EPOCH): \n",
        "\n",
        "    print('Epoch {}/{}'.format(epoch, EPOCH - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    total = 0   \n",
        "    correct = 0 \n",
        "\n",
        "    for i, (x, y) in enumerate(trainloader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        x = x.reshape(-1, sequence_length, input_size)\n",
        "\n",
        "        yhat = model(x)\n",
        "        loss = loss_func(yhat, y)  \n",
        "\n",
        "        optimizer.zero_grad()            \n",
        "        loss.backward()                  \n",
        "        optimizer.step()         \n",
        "      \n",
        "\n",
        "        _, y_pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (y_pred == y.data).sum()\n",
        "\n",
        "    _acc = correct.double()/total\n",
        "    _loss = loss.cpu().detach().numpy()\n",
        "    train_loss.append(_loss)\n",
        "    train_acc.append(_acc)\n",
        "            \n",
        "    _val_acc,_val_loss = validation()\n",
        "    val_loss.append(_val_loss)\n",
        "    val_acc.append(_val_acc)\n",
        "\n",
        "    print('loss: {:.4f} acc: {:.4f} val_loss: {:.4f} val_acc: {:.4f} '.format(_loss,_acc,_val_loss,_val_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys8iPIbsPzwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch = range(len(train_loss))\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,train_loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,train_acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpWXlhDTP6Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_val_acc,_val_loss = validation()\n",
        "\n",
        "print('Test accuracy: {:.4f}'.format(_val_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcbo4QZ4QASi",
        "colab_type": "text"
      },
      "source": [
        "# Topic 8 Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7aEqiF-ZeXo",
        "colab_type": "text"
      },
      "source": [
        "## Pre Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae4x9TXeAQ6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBWXH1aDT3g3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfSl7ztPUx2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd '/content/gdrive/My Drive/data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XfLajFeU1Fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lac7pM46ZVJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "# model = models.resnet18(pretrained=True)\n",
        "# model = models.alexnet(pretrained=True)\n",
        "# model = models.squeezenet1_0(pretrained=True)\n",
        "model = models.vgg16(pretrained=True)\n",
        "# model = models.densenet_161(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiZfetQEZn6H",
        "colab_type": "text"
      },
      "source": [
        "## Load Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpJ7n7AQZm27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path = 'elephant.jpg'\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "img = Image.open(image_path)\n",
        "img_tensor = preprocess(img)\n",
        "img_tensor.unsqueeze_(0)\n",
        "predict = model(img_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsuJuMxJa5-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import requests\n",
        "\n",
        "LABELS_URL = 'http://s3.amazonaws.com/outcome-blog/imagenet/labels.json'\n",
        "labels = {int(key):value for (key, value)\n",
        "          in requests.get(LABELS_URL).json().items()}\n",
        "\n",
        "print(labels[predict.data.numpy().argmax()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C73hu1qc7iR",
        "colab_type": "text"
      },
      "source": [
        "## Fine Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ13ccmUVbPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = 'hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djYrT-Ojf5Yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "for param in model_ft.parameters():\n",
        "    param.requires_grad = True\n",
        "    \n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL5ABrxuhn41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8EfbHmehpvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNgcDPUOkEjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image,label = next(iter(dataloaders['train']))\n",
        "image.shape,label.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwIDY7q-l0wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image,label = next(iter(dataloaders['val']))\n",
        "predict = model_ft(image.to(device))\n",
        "_,predict = torch.max(predict,1)\n",
        "print(predict)\n",
        "print(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0jNuC3mttxb",
        "colab_type": "text"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dywGK2B-5q2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiYw5Idv5_f8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv,exp_lr_scheduler, num_epochs=25)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}